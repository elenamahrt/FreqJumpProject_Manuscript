\documentclass[12pt]{article}
\usepackage{jneurosci}
\usepackage{graphicx}% Include figure files
\textheight 9.2 in
\textwidth 7.125 in
\oddsidemargin -0.3 in
\topmargin -0.7 in
%\renewcommand{\baselinestretch}{2}
\renewcommand{\thefootnote}{\arabic{footnote}}
%========== Math Commands =============================%
\newcommand{\be}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\newcommand{\tri}{\mbox{\scriptsize $\triangle$}}
%======================================================%
% Definition of title page:
%\title{Emergence of receptive fields for efficient encoding in the auditory midbrain}
\title{}

\author {Elena J. Mahrt$^{1}$, 
 Patrick D. Roberts $^{1}$, 
 \and Christine V. Portfors$^{1}$}

\date{\small \it (\today)}
%======================================================%
\begin{document}


\maketitle

\noindent \textbf{1.} School of Biological Sciences, Washington State University Vancouver, WA, USA


\vspace {3mm}

\noindent \textbf{Abbreviated title:}  {\em }\\ \\
%Number of text pages:  , number of figures:  , number of tables:  .\\ \\
%Number of words in abstract:  , words in the introduction: 360 , words in the discussion:  .\\ \\
\textbf{Corresponding author:} Christine V. Portfors,  Washington State University, 14204 NE Salmon Creek Ave., Vancouver, WA, e-mail:portfors@vancouver.wsu.edu, 360-546-9434\\ \\
\textbf{ACKNOWLEDGMENTS}: This work was supported by National Science Foundation Grant No. IOS-0920060 to CVP \\ \\
Keywords:  ultrasonic vocalizations, vocal learning, acoustic communication \\\\

Abstract:  words

Introduction:  words

Discussion:  words

Figures: 0

Tables: 
%


\newpage

\begin{abstract}


\end{abstract}
% 

\newpage
\section{To Think About}
Is it necessary to record distortion products being created by vocalizations using DPOAE measures? Can you defend your answer to Melissa Caras?
Thought: Even if I could measure DPOAE's, interpreting the result will not be easy. If I do NOT detect any DP from vocalizations, it does not necessarily mean they are not being created. The ultra high frequencies present in these vocalizations are not frequently presented during DPOAE recordings, and I am not even sure they have ever been. Furthermore, the amplitude of the predicted DPOAE's created by vocalizations will be very small in amplitude. Thus, it will be difficult to interpret a negative result from a DPOAE experiment (i.e.we may have a false negative).

Why would or would not a good test of DP encoding be to present the first syllable component (or first tone) in one ear and the other component (or tone) in the other ear. DP's require the simultaneous traveling waves to occur on the same basilar membrane. So, we would predict that a neuron evoked by a vocalization presented in only one ear would not respond to parts of the vocalization presented across the two ears. If the latter were the case, then I would expect the cell to respond to both components, regardless of how long they are overlapped. But our preliminary data shows that the amount of overlap is important for some cells, and thus that input from only one ear is necessary for encoding. However, what if the cells are selective for overlap because they are combination AND delay sensitive, sort of like bat IC cells? What would the anatomical mechanism for this be? Has the mechanism been explained in bats?

\section{Outline}
\section*{Introduction}

%From proposal aim: To determine encoding mechanisms for ultrasonic vocalizations in the mouse IC} 
%This is NOT a compelling first paragraph. But it is at least something to play with.
Speech is a fundamental means of communication and a variety of communication disorders occur because of disruptions in vocal production or encoding systems. Determining the mechanisms of normal vocal production and encoding will increase the understanding of neural causes of these disorders. Mice are potentially an excellent model organism for studying mechanisms of vocal communication because their genetics are well-studied and they vocalize in many social contexts. Mice communicate via complex ultrasonic vocalizations emitted in discrete units of continuous sound, called syllables. Each syllable is spectrally and temporally modulated in identifiable patterns, allowing for classification into syllable categories. One such category is the frequency jump. These syllables are comprised of multiple frequency components separated by 10-30 kHz and briefly overlapped by 2-3 ms. If mice are to be used as a model system for communication and associated disorders, it is important to achieve the aims presented in this proposal of (1) determining whether mouse vocalizations are learned, (2) how they are emitted, and (3) how they are encoded. 

\textbf{Specific Aim 3: To determine how mice encode their ultrasonic vocalizations in the inferior colliculus.} 
Speech perception is a complex neurological process that requires the most salient information be correctly parsed out of complex sounds. Neural mechanisms of complex sound encoding are poorly understood, however. The inferior colliculus (IC) is a major auditory midbrain nucleus in the auditory pathway that integrates many ascending and descending inputs \cite{Adams79, Saldana96}. It is also thought to be the first nucleus where selectivity for vocalizations occurs \cite{xiediffering2005}. In mice, some IC neurons are selective for ultrasonic vocalizations that only contain frequencies well above the range of pure tone frequencies that the neuron is tuned to \cite{portforsover-representation2009, portforsmismatch2013, holmstromefficient2010}. The mechanisms for this vocalization selectivity are not entirely known. I will determine what some of these mechanisms are by completing two sub-aims. \textbf{\underline{Aim 3a:} to determine whether distortion products are a mechanism for jump syllable encoding in the mouse IC.} My \textbf{hypothesis} is that the overlapped components in frequency jump syllables create low frequency distortion products that fall within the receptive field of low-tuned IC neurons. \textbf{\underline{Aim 3b:} to determine whether inhibition in the IC contributes to selectivity for jump syllables.} I \textbf{hypothesize} that local inhibition in the IC acts to filter what distortion products, and thus what vocalizations, neurons respond to. My \textbf{approach} for both Aim 3a and 3b is to record the extracellular responses of single IC neurons of awake mice while manipulating the amount of overlap present in synthesized jump syllables. These experiments will be conducted under normal conditions (Aim 3a) and while iontophoretically blocking GABA-A and glycine receptors (Aim 3b). The results of this aim are \textit{significant} because they will provide insight into the neural mechanisms involved in creating selectivity to ultrasonic social vocalizations. 

Mice emit their ultrasonic vocalizations between 50 and 100 kHz \cite{nyby1976social, Nyby83, portforstypes2007} but their auditory system is most sensitive to frequencies between 10 and 30 kHz \cite{ehretfrequency1975}. Despite this mismatch, many neurons in the IC respond selectively to ultrasonic vocalizations comprised of only frequencies above their spectral receptive fields \cite{portforsover-representation2009, holmstromefficient2010}. Previous work has shown that neurons with spectral receptive fields that include only low frequencies will also respond to combinations of simultaneous high frequency tones if the difference between the tones matches the spectral receptive field of the neuron \cite{portforsover-representation2009, mcalpineneural2004}. It has been suggested that these neurons are responding to distortion products created by the combination of high frequencies \cite{portforsover-representation2009}. Distortion products are secondary waves on the basilar membrane of the cochlea created by the interaction of two simultaneous primary waves \cite{roblestwo-tone1991, coopermechanical1997}. These distortion products have been measured in animals such as guinea pigs \cite{mcalpineneural2004}, gerbils \cite{abelsensitive2009}, mice \cite{portforsover-representation2009} and mosquitoes \cite{pennetiersinging2010}. Whether these distortion products help create selectivity to natural vocalizations in the mouse IC has not been explicitly studied, however. The \textbf{objective} of \underline{(Aim 3a)} is to determine how mice encode ultrasonic social vocalizations that fall outside of their best hearing range. 

While responses to distortion products are known to occur in the auditory nerve \cite{goldsteinneural1968}, not all IC neurons respond to distortion products as predicted based on their spectral receptive fields. This suggests that some inputs from distortion products are filtered out at the level of the IC. One potential mechanism for filtering responses to distortion products is through local inhibition. Inhibition of distortion products at the level of the IC may contribute to selectivity for vocalizations that create distortion products. The \textbf{objective} of \underline{(Aim 3b)} is to determine whether inhibition contributes to selectivity to frequency jump syllables. 

\paragraph{Rationale and preliminary data}

\subsubsection*{Aim 3a: Are distortion products important for encoding ultrasonic jump syllables?}
Careful analysis of mouse vocalizations, as done in Aim 1, revealed that jump syllables have ultrasonic components briefly overlapped for 2-3 ms and separated by 10-30 kHz. Because these high frequency components occur simultaneously, they should create distortion products at lower frequencies. These low frequency distortion products will fall within the spectral receptive field of some low tuned IC neurons. This mechanism may help explain why low tuned IC neurons are evoked by high frequency vocalizations \cite{portforsover-representation2009, portforsmismatch2013}.

In this aim, I will test whether neurons are selective for the overlap of high frequency components in frequency jump syllables. \textbf{My hypothesis for Aim 3a is that some low tuned neurons in the IC are selective for low frequency distortion products created by overlapping high frequency components in frequency jump syllables.} To test this hypothesis I will manipulate the amount of temporal overlap of components in frequency jump syllables while recording extracellularly from well-isolated single IC neurons in awake mice.


\section*{\label{sec:methods}Materials and Methods}
\vspace{3mm}
\textbf{Animals}
XX female and XX male CBA/CaJ mice, x-y weeks of age, were used in this experiment. Animals were housed with same-sex litter mates until the day of surgery. All mice were provided with \textit{ad libitum} food and water and maintained on a reversed 12 h light/dark cycle. All animal care and experimental procedures followed the guidelines of the National Institutes of Health, and were approved by the Washington State University Institutional Animal Care and Use Committee (protocol number xxxxxxx).


\vspace{3mm}
\textbf{Surgical procedures}
The surgical procedures used in this study have previously been described in detail \cite{muniakpreparation2012}. Briefly, mice were anesthetized with isoflurane inhalation and placed on a heating pad to maintain body temperature. A midline in incision was made on the scalp and the skin was reflected laterally, exposing bregma and lambda sutures (do I need to reference mouse brain atlas?). Auxiliary muscles concealing bregma were reflected laterally using Gelfoam (company information here). The location of left IC was identified using stereotaxic coordinates relative to bregma. A 1$^{2}$ mm craniotomy over the previously located left IC was performed using a sharp scalpel tip. A custom made metal head post was cemented to the skull on the bregma and midline suture intersection. A tungsten ground pin was placed just through the skull over right cerebral cortex between lambda and bregma. At the end of surgery, Bonewax (company information here) was applied over the craniotomy. The animal was allowed to recover for at least one day prior to the start of an experiment. Neosporin was applied to exposed tissue and ketoprofin (0.05 mg/kg) and lidocaine gel were provided for pain management. 


\vspace{3mm}
\textbf{Acoustic stimulation}

The stimuli used in this experiment were either pure tones or recorded vocalizations. Pure tones specs here. 
Vocalization stimuli consisted of a suite of 12 syllables manually selected from a catalog of 21,251 male vocalizations previously recorded \cite{mahrtengineered2013}. All syllables were representative examples from the frequency jump category that exhibited acoustic and temporal parameters typical of that category, as described in \cite{mahrtengineered2013}.  These syllables ranged between xx and yy ms in duration and encompassed between xx and yy kHz. Each syllable was specifically selected to include a frequency jump size (explain?) between 13 and 25 kHz (check this).


Sounds were presented via a free-field speaker (EMIT high energy speaker, Infinity Systems) 10 cm and 45 degrees from the animal's right ear. The speaker was regularly calibrated using a B&K condenser microphone placed at the position of the animal's ear... 

\subsection{Distorted stimuli via Cochlea response model}
Started with same vocalizations and components as described previously, but ran them through a cochlea response model, which has been described in detail in [cite Pat's 2015 (?) DCN paper]. Briefly, this nonlinear model of the cochlea included reverberation of traveling waves on the basilar membrane. This reverberation contributes to the creation of distortion products. (where does the reverberation come from? the outer hair cells?) With this model we were able to create stimuli with sound at similar frequencies and intensities as the predicted distortions created by high frequencies in the vocalizations them selves. Stimuli were low pass filtered at 40 kHz with a Butterworth window (is that right?) Krohn Hite blah blah blah filter to ensure that only low frequency distortion frequencies were presented. Neuronal responses to the natural vocalizations were compared to the vocalizations run through the cochlea response model. 

\vspace{3mm}
\textbf{Data acquisition and analysis}



\vspace{3mm}
\noindent \textit{Statistical analysis}

To compare response firing rates (absolute) consider using Wilcoxon rank-sum tests. Used in Shepard, Lin et. al. 2015 


% Results and Discussion can be combined.
\section*{\label{sec:results}Results}
\textit{Things to include in Results section:} 

We recorded from a total of XX IC neurons from YY mice. Of these XX neurons, ZZ were evoked by vocalizations presented at j dB SPL. The amount of vocalization selectivity seen in the data from this study is comparable to past work \cite{holmstromefficient2010}.

TT/ZZ neurons were evoked by vocalizations because their tuning directly overlapped with the frequencies in the vocalizations.

II/ZZ neurons are strictly evoked by the distortion product created by overlapping components in jump syllables. 

MM/ZZ neurons respond to vocalizations because they are evoked by the individual components in the syllables. 



\section*{\label{sec:discussion}Discussion}

\textit{Things to include in Discussion section:} 
It is important to emphasize that we are not advocating that mouse ultrasonic vocalizations are encoded \textit{only} via distortion products. Previous work, and data in this study, have shown that mid- to high-tuned neurons will encode high frequency vocalizations because their broad frequency response areas overlap with the frequencies in vocalizations. Rather, this study intends to explain why low-tuned neurons respond to vocalizations when their frequency tuning is no where near the frequencies in the vocalizations that they respond to. 

What role does duration selectivity play in relation to vocalization selectivity? It is well documented that IC neurons in mouse, bat, and other species are selective for pure tones of particular durations. It has always been speculated that this duration selectivity is a mechanism for vocalization selectivity, but no experiment has explicitly shown this. In this study, we showed that some mouse IC neurons are selective for vocalizations of a particular duration. %or you can say: Duration selectivity is a contributing mechanism in vocalization selectivity by some IC neurons. 
Importantly, our results show that low-tuned duration selective IC neurons are not responding to the duration of the whole vocalization, but rather only to the low frequency distortions created by the vocalizations. Thus, the actual vocalization signal received by IC neurons is much shorter than what is presented at the ear. 

\newpage

\bibliographystyle{jneurosci}
\bibliography{20141026ElenaBibliography}

\newpage

%\section*{Figure Legends}
\section*{\label{sec:legends}Figure Legends}



\end{document}
